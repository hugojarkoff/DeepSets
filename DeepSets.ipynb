{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DeepSets\n",
    "## Permutation Invariant Neural Networks\n",
    "\n",
    "This notebook is focused on DeepSets, a neural network architecture that takes into input sets rather than fixed dimensional vectors, and whose output should be invariant to permutation of this set. You will learn what is DeepSets, how it works, and implement yourself a DeepSets network that learns to compute the sum of any set of MNIST Digits, based on PyTorch. \n",
    "<br> \n",
    "<br>\n",
    "This notebook is based on mainly two article : [Zaheer et al., 2017](https://arxiv.org/abs/1703.06114) which first introduced and applied the concept in 2017, and the response of [Wagstaff et al., 2019](https://arxiv.org/abs/1901.09006) on the limitations of this method of representing functions on sets. Both paper can be found in the /biblio repository. The code is inspired by [this Github repository](https://github.com/yassersouri/pytorch-deep-sets), by Yasser Souri.\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "#### First let's import a few modules while you read the intro. You might need to install tensorboardX, use pip ! (pip install tensorboardX)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torchvision\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import FloatTensor\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.transforms import Compose, ToTensor, Normalize\n",
    "from torch import optim\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "from typing import Tuple\n",
    "from typing import Union\n",
    "from tqdm import tqdm\n",
    "\n",
    "RANDOM_SEED = 0\n",
    "DATA_ROOT = './datasets/'\n",
    "NetIO = Union[FloatTensor, Variable]\n",
    "MNIST_TRANSFORM = Compose([ToTensor(), Normalize((0.1307,), (0.3081,))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0 - Introduction\n",
    "\n",
    "Most successful deep learning approaches make use of the *structure* in their inputs: CNNs are the state-of-the-art for images, RNNs and temporal convolutions for sequences, etc. The success of convolutional networks boils down to exploiting a key invariance property: translation invariance. \n",
    "\n",
    "But images and sequences are far from the only data we want to build neural networks for. Often our inputs are sets: sequences of items, where the ordering of items caries no information for the task in hand. In such a situation, the invariance property we can exploit is **permutation invariance**. Such problems are frequent, for instance parsing a scene composed of a set of objects ([Eslami et al., 2016](https://arxiv.org/abs/1603.08575)), making predictions from a set of points forming a 3D point cloud ([Qi et al., 2017](https://arxiv.org/abs/1612.00593)) or training a set of agents in reinforcement learning ([Sunehag et al., 2017](https://www.sciencedirect.com/science/article/pii/S240589631932035X)). In the original paper, the authors [Zaheer et al., 2017](https://arxiv.org/abs/1703.06114) applied it in cosmology by improving red-shift estimation and anomaly detection in celebrities faces databases ! The model showed both qualitative and quantitative results in every case.\n",
    "\n",
    "\n",
    "**Note** : Another feature discussed in the original paper is *permutation equivariance* . However, since it is a relatively different concept from *invariance*, and do not apply in the same way, nor to the same goal, we will discuss it in the Appendix. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I - Permutation Invariance\n",
    "\n",
    "Intuitively, permutation invariances states that the output of the model must not change if the inputs are reordered. For instance, this is what a permutation invariant function with three inputs would look like : $ f(a,b,c) = f(b,a,c) = f(b,c,a) = \\cdots $. More mathematically speaking, the exact definition is the following:\n",
    "\n",
    "<div class=\"alert alert-success\" style=\"margin-top: 1em\">\n",
    "A function $f(\\mathbf{x})$ is <i>permutation invariant</i> if $f(\\{x_1, ... , x_M\\}) = f(\\{x_{\\pi(1)}, ... , x_{\\pi(M)}\\})$ for any permutation $\\pi$.\n",
    "</div> \n",
    "\n",
    "Having this in my mind, how do we define permutation-invariant neural networks? Remember, we need to define a model that does not rely on the order of its inputs.\n",
    "\n",
    "The main idea is to make use of some operation $P$ that is already permutation invariant. We map each of our inputs separately to another space, and apply to them our $P$ to obtain a representation of the set as a whole. $P$ destroys the ordering information, leaving the overall model permutation invariant.\n",
    "\n",
    "In particular, <i>DeepSets</i> does this by setting $P$ to be summation on the latent space $Z$. Other operations are used as well, e.g. elementwise max. We call the case where the sum is used <i>sum-decomposition via the latent space</i> : \n",
    "\n",
    "\n",
    "<div class=\"alert alert-success\" style=\"margin-top: 1em\">\n",
    "    A function $f$ is <i>sum-decomposable</i> if there are functions $\\rho$ and $\\phi$ such that : \\[f(X) = \\rho(\\sum_{x \\in X} \\phi(x))\\]\n",
    "    In this case, we say that $(\\rho,\\phi)$ is a <i>sum-decomposition</i> of $f$. The codomain of $\\phi$ (hence, the domain of $\\rho$) is called the <i>latent space</i> $Z$.\n",
    "</div>\n",
    "\n",
    "We can now introduce the main backbone theorem for our work:\n",
    "\n",
    "<div class=\"alert alert-success\" style=\"margin-top: 1em\">\n",
    "    We denote by $\\mathcal{P}(\\mathfrak{X}) $ the power set of $\\mathfrak{X}$, i.e the set of the sets of $\\mathfrak{X}$.\n",
    "    Let $f : \\mathcal{P}(\\mathfrak{X}) \\rightarrow \\mathbb{R}$ where $\\mathfrak{X}$ is $\\textbf{countable}$ (i.e, its cardinality is smaller or equal to the number of elements in $\\mathbb{N}$. This includes both finite and countably infinite sets; e.g. $\\mathbb{N}$, $\\mathbb{Q}$, and subsets thereof). Then <b>$f$ is permutation-invariant if and only if it is sum-decomposable via the latent space $\\mathbb{R}$</b>.\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-danger\"><a href=\"#answer3\" data-toggle=\"collapse\"><b>Proof; you may try to do it as an exercice! (click to expand)</b></a><br>\n",
    "<div id=\"answer3\" class=\"collapse\">\n",
    "    \n",
    "Since $\\mathfrak{X}$ is countable, each $x \\in \\mathfrak{X}$ can be mapped to a unique element in $\\mathbb{N}$ by a function $c(x) : \\mathfrak{X} \\rightarrow \\mathbb{N}$. Let $\\Phi(X) = \\sum_{􏰄x \\in X} \\phi(x)$. If we can choose $\\phi$ so that $\\Phi$ is injective, then we can set $\\rho = f ◦ \\Phi^{−1}$, giving \\begin{equation} f = \\rho ◦ \\Phi = \\rho(\\sum_{x \\in X} \\phi(x)) \\quad \\text{i.e, $f$ is sum-decomposable via $\\mathbb{R}$.}\\end{equation} \n",
    "Now, consider $\\phi(x) = 4^{-c(x)}$. Under this mapping, each $X \\subset \\mathfrak{X}$ corresponds to a unique real number expressed in base 4. Therefore $\\Phi$ is injective, hence the theorem.\n",
    "</div>\n",
    "</div>\n",
    "\n",
    "Great ! We now have a fully-functional theorem that states that if we can sum-decompose our network to $\\mathbb{R}$, then it is permutation-invariant. The high-level description of the full architecture is now reasonably straightforward - transform your inputs into some latent space, destroy the ordering information in the latent space by applying the sum, and then transform from the latent space to the final output. This is illustrated in the following figure:\n",
    "\n",
    "<img src=\"img/DeepSets_structure.png\" width=\"600px\"></img>\n",
    "\n",
    "Replacing $\\phi$ and $\\rho$ by universal approximators leaves matters unchanged, since, in particular, $\\phi$ and $\\rho$ can be used to approximate arbitrary polynomials. Therefore, we can develop our own DeepSet network by learning these approximator!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II - Implementation : MNIST digits sum\n",
    "In this applied section, we want to build a network than learns to compute **any sum** of **any set** of MNIST Digits using DeepSets. \n",
    "Why not use a classic Neural Network and train it to add its inputs? Let's look at the following picture.\n",
    "<br>\n",
    "<img src=\"img/simpleNN.png\" width=\"500px\"></img>\n",
    "<br>\n",
    "Well this would certainly work for a fixed number N of digits. But remember, we want to be able to compute the sum of **any number M of digits** ! We would need to retrain the network on this new number of inputs, which isn't ideal... Would a recurrent network work then?\n",
    "<br>\n",
    "<img src=\"img/rNN.png\" width=\"500px\"></img>\n",
    "\n",
    "\n",
    "It could work. However, we have **no guaranty** that the sum of digits will remain the same if you switch two or more digits. Which is why we will use DeepSets, which has this nice property !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of, let's define a class that instantiates a set of MNIST and returns its correct sum based on the labels of the MNIST digits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This class instantiates a set of MNIST and returns its sum based on the label (targets) of the MNIST digits\n",
    "# min_len : minimum length of the sets generated\n",
    "# max_len : maximum length of the sets generated\n",
    "# dataset_len : length of the dataset, ie. how many sets of MNIST digits there is\n",
    "\n",
    "class MNISTSummation(Dataset):\n",
    "    def __init__(self, min_len: int, max_len: int, dataset_len: int, train: bool = True, transform: Compose = None):\n",
    "        self.min_len = min_len\n",
    "        self.max_len = max_len\n",
    "        self.dataset_len = dataset_len\n",
    "        self.train = train\n",
    "        self.transform = transform\n",
    "        \n",
    "        self.mnist = MNIST(DATA_ROOT, train=self.train, transform=self.transform, download=True)\n",
    "        \n",
    "        mnist_len = self.mnist.__len__()\n",
    "        mnist_items_range = np.arange(0, mnist_len)\n",
    "\n",
    "        items_len_range = np.arange(self.min_len, self.max_len + 1)\n",
    "        items_len = np.random.choice(items_len_range, size=self.dataset_len, replace=True)\n",
    "        self.mnist_items = []\n",
    "        for i in range(self.dataset_len):\n",
    "            self.mnist_items.append(np.random.choice(mnist_items_range, size=items_len[i], replace=True))\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return self.dataset_len\n",
    "\n",
    "    def __getitem__(self, item: int) -> Tuple[FloatTensor, FloatTensor]:\n",
    "        mnist_items = self.mnist_items[item]\n",
    "\n",
    "        the_sum = 0\n",
    "        images = []\n",
    "        for mi in mnist_items:\n",
    "            img, target = self.mnist.__getitem__(mi)\n",
    "            the_sum += target\n",
    "            images.append(img)\n",
    "\n",
    "        return torch.stack(images, dim=0), torch.FloatTensor([the_sum])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test it for a batch of 5 sets, each having a length between 2 and 10. This is so we can visualize sets of digits of different length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------\n",
      "Correct sum of the MNIST digits  :  39.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "dark"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------\n",
      "Correct sum of the MNIST digits  :  16.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "dark"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------\n",
      "Correct sum of the MNIST digits  :  16.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "dark"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------\n",
      "Correct sum of the MNIST digits  :  29.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "dark"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------\n",
      "Correct sum of the MNIST digits  :  39.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "dark"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset_length = 5\n",
    "\n",
    "MNISTSum = MNISTSummation(min_len=2, max_len=10, dataset_len=dataset_length, train=True, transform=MNIST_TRANSFORM)\n",
    "\n",
    "for i in range(dataset_length):\n",
    "    img = MNISTSum.__getitem__(i)\n",
    "    print(\"-------------------------------------------------------\")\n",
    "    print(\"Correct sum of the MNIST digits  : \",img[1].item())\n",
    "    plt.imshow(torchvision.utils.make_grid(img[0], nrow=10).permute(1, 2, 0), cmap='gray')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It works! Great. Now let's define the $\\phi$ and $\\rho$ functions of our DeepSets model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SmallMNISTCNNPhi(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc1_drop = nn.Dropout2d()\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, x: NetIO) -> NetIO:\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = self.conv2_drop(self.conv2(x))\n",
    "        x = F.relu(F.max_pool2d(x, 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc1_drop(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        return x\n",
    "\n",
    "\n",
    "class SmallRho(nn.Module):\n",
    "    def __init__(self, input_size: int, output_size: int = 1):\n",
    "        super().__init__()\n",
    "\n",
    "        self.input_size = input_size\n",
    "        self.output_size = output_size\n",
    "\n",
    "        self.fc1 = nn.Linear(self.input_size, 10)\n",
    "        self.fc2 = nn.Linear(10, self.output_size)\n",
    "\n",
    "    def forward(self, x: NetIO) -> NetIO:\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now define our own DeepSets ! Your turn to work. Based on the figure in the first part, and the explanations, complete the DeepSets model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Complete the code below!\n",
    "# If you get stuck, uncomment the line in the next cell to load a correction (then you can execute the code).\n",
    "\n",
    "class InvariantModel(nn.Module):\n",
    "    def __init__(self, phi: nn.Module, rho: nn.Module):\n",
    "        super().__init__()\n",
    "        self.phi = phi\n",
    "        self.rho = rho\n",
    "\n",
    "    def forward(self, x: NetIO) -> NetIO:\n",
    "        \n",
    "        # Complete here !\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# True solution : uncomment and execute the line below\n",
    "#%load solution/solution.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Good job ! Now we can define our final model that will learn to sum up the digits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DeepSets Model that sums up the digits. For better performance, use a dataset_len >10000 for training and testing\n",
    "# This allows the model to train better.\n",
    "\n",
    "class SumOfDigits(object):\n",
    "    def __init__(self, lr=1e-3, wd=5e-3): #learning rate, weight decay \n",
    "        self.lr = lr\n",
    "        self.wd = wd\n",
    "        \n",
    "        self.train_db = MNISTSummation(min_len=2, max_len=30, dataset_len=2000, train=True, transform=MNIST_TRANSFORM)\n",
    "        self.test_db = MNISTSummation(min_len=2, max_len=30, dataset_len=2000, train=False, transform=MNIST_TRANSFORM)\n",
    "\n",
    "        self.the_phi = SmallMNISTCNNPhi()\n",
    "        self.the_rho = SmallRho(input_size=10, output_size=1)\n",
    "\n",
    "        self.model = InvariantModel(phi=self.the_phi, rho=self.the_rho)\n",
    "        if torch.cuda.is_available():\n",
    "            self.model.cuda()\n",
    "\n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr=self.lr, weight_decay=self.wd)\n",
    "\n",
    "        self.summary_writer = SummaryWriter(\n",
    "            log_dir='./logs/exp-lr:%1.5f-wd:%1.5f/' % (self.lr, self.wd))\n",
    "\n",
    "        \n",
    "    # Train a complete epoch\n",
    "    def train_1_epoch(self, epoch_num: int = 0):\n",
    "        self.model.train()\n",
    "        for i in tqdm(range(len(self.train_db))): \n",
    "            loss = self.train_1_item(i)\n",
    "            self.summary_writer.add_scalar('train_loss', loss, i + len(self.train_db) * epoch_num)\n",
    "\n",
    "    # Train a single MNIST digit set\n",
    "    def train_1_item(self, item_number: int) -> float:\n",
    "        x, target = self.train_db.__getitem__(item_number)\n",
    "        if torch.cuda.is_available():\n",
    "            x, target = x.cuda(), target.cuda()\n",
    "\n",
    "        x, target = Variable(x), Variable(target)\n",
    "\n",
    "        self.optimizer.zero_grad()\n",
    "        pred = self.model.forward(x)\n",
    "        the_loss = F.mse_loss(pred, target)\n",
    "\n",
    "        the_loss.backward()\n",
    "        self.optimizer.step()\n",
    "\n",
    "        the_loss_tensor = the_loss.data\n",
    "        if torch.cuda.is_available():\n",
    "            the_loss_tensor = the_loss_tensor.cpu()\n",
    "\n",
    "        the_loss_numpy = the_loss_tensor.numpy().flatten()\n",
    "        the_loss_float = float(the_loss_numpy[0])\n",
    "\n",
    "        return the_loss_float\n",
    "\n",
    "    # Evaluate the quality of prediction\n",
    "    def evaluate(self):\n",
    "        \n",
    "        self.model.eval()\n",
    "        \n",
    "        totals = [0] * 51\n",
    "        corrects = [0] * 51\n",
    "\n",
    "        for i in tqdm(range(len(self.test_db))):\n",
    "            \n",
    "            x, target = self.test_db.__getitem__(i)\n",
    "            \n",
    "            item_size = x.shape[0]\n",
    "\n",
    "            if torch.cuda.is_available():\n",
    "                x = x.cuda()\n",
    "\n",
    "            pred = self.model.forward(Variable(x)).data\n",
    "\n",
    "            if torch.cuda.is_available():\n",
    "                pred = pred.cpu().numpy().flatten()\n",
    "\n",
    "            pred = int(round(float(pred[0])))\n",
    "            target = int(round(float(target.numpy()[0])))\n",
    "\n",
    "            totals[item_size] += 1\n",
    "\n",
    "            if pred == target:\n",
    "                corrects[item_size] += 1\n",
    "\n",
    "        totals = np.array(totals)\n",
    "        corrects = np.array(corrects)\n",
    "    \n",
    "        print(\"Totals: \",totals)\n",
    "        print(\"Corrects: \",corrects)\n",
    "        \n",
    "        print(corrects / totals)\n",
    "    \n",
    "    # Simple function for you to test and visualize the model performance\n",
    "    def test_after_training(self, x_test):\n",
    "        pred_test = self.model.forward(Variable(x_test)).data\n",
    "        pred_test = int(round(float(pred_test[0])))\n",
    "        return pred_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's train our model. \n",
    "<br>\n",
    "<br>\n",
    "For better results, I recommend changing the dataset_len to 10000 (**at least**) in the previous class SumOfDigits, and train our model on 30-35 iterations below.\n",
    "<br>\n",
    "<br>\n",
    "However **be careful, this might be REALLY heavy for your computer**. You might want to launch it on Google Colab or any other external GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2000 [00:00<?, ?it/s]/Users/hugo/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:42: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([1, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "100%|██████████| 2000/2000 [00:19<00:00, 103.07it/s]\n",
      "100%|██████████| 2000/2000 [00:08<00:00, 240.02it/s]\n",
      "/Users/hugo/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:92: RuntimeWarning: invalid value encountered in true_divide\n",
      "  1%|          | 13/2000 [00:00<00:16, 117.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Totals:  [ 0  0 64 62 50 56 72 82 76 70 65 52 58 87 79 76 62 71 61 79 56 62 79 66\n",
      " 77 78 68 69 80 67 76  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0]\n",
      "Corrects:  [0 0 6 7 2 3 2 5 3 6 2 2 5 2 1 3 2 5 2 0 0 3 2 0 2 3 1 4 2 3 3 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[       nan        nan 0.09375    0.11290323 0.04       0.05357143\n",
      " 0.02777778 0.06097561 0.03947368 0.08571429 0.03076923 0.03846154\n",
      " 0.0862069  0.02298851 0.01265823 0.03947368 0.03225806 0.07042254\n",
      " 0.03278689 0.         0.         0.0483871  0.02531646 0.\n",
      " 0.02597403 0.03846154 0.01470588 0.05797101 0.025      0.04477612\n",
      " 0.03947368        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:20<00:00, 98.77it/s] \n",
      "100%|██████████| 2000/2000 [00:08<00:00, 244.57it/s]\n",
      "  1%|          | 11/2000 [00:00<00:18, 109.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Totals:  [ 0  0 64 62 50 56 72 82 76 70 65 52 58 87 79 76 62 71 61 79 56 62 79 66\n",
      " 77 78 68 69 80 67 76  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0]\n",
      "Corrects:  [0 0 5 5 6 4 1 5 3 6 5 0 0 5 3 3 3 4 0 1 1 0 2 3 1 0 3 2 0 1 3 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[       nan        nan 0.078125   0.08064516 0.12       0.07142857\n",
      " 0.01388889 0.06097561 0.03947368 0.08571429 0.07692308 0.\n",
      " 0.         0.05747126 0.03797468 0.03947368 0.0483871  0.05633803\n",
      " 0.         0.01265823 0.01785714 0.         0.02531646 0.04545455\n",
      " 0.01298701 0.         0.04411765 0.02898551 0.         0.01492537\n",
      " 0.03947368        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:19<00:00, 104.71it/s]\n",
      "100%|██████████| 2000/2000 [00:08<00:00, 241.85it/s]\n",
      "  0%|          | 8/2000 [00:00<00:25, 79.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Totals:  [ 0  0 64 62 50 56 72 82 76 70 65 52 58 87 79 76 62 71 61 79 56 62 79 66\n",
      " 77 78 68 69 80 67 76  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0]\n",
      "Corrects:  [0 0 9 9 7 6 4 5 6 2 2 2 3 3 3 7 1 5 1 2 3 5 1 2 7 4 3 0 5 2 2 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[       nan        nan 0.140625   0.14516129 0.14       0.10714286\n",
      " 0.05555556 0.06097561 0.07894737 0.02857143 0.03076923 0.03846154\n",
      " 0.05172414 0.03448276 0.03797468 0.09210526 0.01612903 0.07042254\n",
      " 0.01639344 0.02531646 0.05357143 0.08064516 0.01265823 0.03030303\n",
      " 0.09090909 0.05128205 0.04411765 0.         0.0625     0.02985075\n",
      " 0.02631579        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:20<00:00, 99.32it/s] \n",
      "100%|██████████| 2000/2000 [00:09<00:00, 220.70it/s]\n",
      "  0%|          | 10/2000 [00:00<00:20, 95.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Totals:  [ 0  0 64 62 50 56 72 82 76 70 65 52 58 87 79 76 62 71 61 79 56 62 79 66\n",
      " 77 78 68 69 80 67 76  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0]\n",
      "Corrects:  [0 0 6 9 7 2 6 9 5 5 2 4 5 9 7 3 6 2 4 3 3 4 6 1 1 7 0 5 4 4 5 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[       nan        nan 0.09375    0.14516129 0.14       0.03571429\n",
      " 0.08333333 0.1097561  0.06578947 0.07142857 0.03076923 0.07692308\n",
      " 0.0862069  0.10344828 0.08860759 0.03947368 0.09677419 0.02816901\n",
      " 0.06557377 0.03797468 0.05357143 0.06451613 0.07594937 0.01515152\n",
      " 0.01298701 0.08974359 0.         0.07246377 0.05       0.05970149\n",
      " 0.06578947        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:18<00:00, 106.80it/s]\n",
      "100%|██████████| 2000/2000 [00:08<00:00, 247.40it/s]\n",
      "  1%|          | 12/2000 [00:00<00:17, 115.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Totals:  [ 0  0 64 62 50 56 72 82 76 70 65 52 58 87 79 76 62 71 61 79 56 62 79 66\n",
      " 77 78 68 69 80 67 76  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0]\n",
      "Corrects:  [ 0  0 15  7  4  4  2  6  7  8  8  2  5  5  6  2  2  3  3  4  2  2  3  2\n",
      "  1  4  3  3  1  2  4  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0]\n",
      "[       nan        nan 0.234375   0.11290323 0.08       0.07142857\n",
      " 0.02777778 0.07317073 0.09210526 0.11428571 0.12307692 0.03846154\n",
      " 0.0862069  0.05747126 0.07594937 0.02631579 0.03225806 0.04225352\n",
      " 0.04918033 0.05063291 0.03571429 0.03225806 0.03797468 0.03030303\n",
      " 0.01298701 0.05128205 0.04411765 0.04347826 0.0125     0.02985075\n",
      " 0.05263158        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:20<00:00, 98.83it/s] \n",
      "100%|██████████| 2000/2000 [00:09<00:00, 212.04it/s]\n",
      "  1%|          | 12/2000 [00:00<00:16, 118.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Totals:  [ 0  0 64 62 50 56 72 82 76 70 65 52 58 87 79 76 62 71 61 79 56 62 79 66\n",
      " 77 78 68 69 80 67 76  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0]\n",
      "Corrects:  [ 0  0 10 10  8  5  5  4  5  2  1  2  4  6  5  6  3  4  6  2  1  2  1  4\n",
      "  5  2  5  2  3  1  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0]\n",
      "[       nan        nan 0.15625    0.16129032 0.16       0.08928571\n",
      " 0.06944444 0.04878049 0.06578947 0.02857143 0.01538462 0.03846154\n",
      " 0.06896552 0.06896552 0.06329114 0.07894737 0.0483871  0.05633803\n",
      " 0.09836066 0.02531646 0.01785714 0.03225806 0.01265823 0.06060606\n",
      " 0.06493506 0.02564103 0.07352941 0.02898551 0.0375     0.01492537\n",
      " 0.03947368        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:19<00:00, 100.30it/s]\n",
      "100%|██████████| 2000/2000 [00:08<00:00, 227.15it/s]\n",
      "  0%|          | 10/2000 [00:00<00:19, 99.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Totals:  [ 0  0 64 62 50 56 72 82 76 70 65 52 58 87 79 76 62 71 61 79 56 62 79 66\n",
      " 77 78 68 69 80 67 76  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0]\n",
      "Corrects:  [ 0  0 15 10  8  4  6  6  2  6  2  3  8  0  4  6  3  3  7  3  3  2  3  3\n",
      "  2  2  2  1  1  2  5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0]\n",
      "[       nan        nan 0.234375   0.16129032 0.16       0.07142857\n",
      " 0.08333333 0.07317073 0.02631579 0.08571429 0.03076923 0.05769231\n",
      " 0.13793103 0.         0.05063291 0.07894737 0.0483871  0.04225352\n",
      " 0.1147541  0.03797468 0.05357143 0.03225806 0.03797468 0.04545455\n",
      " 0.02597403 0.02564103 0.02941176 0.01449275 0.0125     0.02985075\n",
      " 0.06578947        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:19<00:00, 102.83it/s]\n",
      "100%|██████████| 2000/2000 [00:08<00:00, 222.35it/s]\n",
      "  1%|          | 13/2000 [00:00<00:16, 119.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Totals:  [ 0  0 64 62 50 56 72 82 76 70 65 52 58 87 79 76 62 71 61 79 56 62 79 66\n",
      " 77 78 68 69 80 67 76  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0]\n",
      "Corrects:  [ 0  0 12 10  7  4  6  4  4  5  3  4  2  0  3  1  1  2  0  0  2  0  0  2\n",
      "  1  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0]\n",
      "[       nan        nan 0.1875     0.16129032 0.14       0.07142857\n",
      " 0.08333333 0.04878049 0.05263158 0.07142857 0.04615385 0.07692308\n",
      " 0.03448276 0.         0.03797468 0.01315789 0.01612903 0.02816901\n",
      " 0.         0.         0.03571429 0.         0.         0.03030303\n",
      " 0.01298701 0.01282051 0.         0.         0.         0.\n",
      " 0.                nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:19<00:00, 103.07it/s]\n",
      "100%|██████████| 2000/2000 [00:08<00:00, 236.10it/s]\n",
      "  0%|          | 8/2000 [00:00<00:25, 78.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Totals:  [ 0  0 64 62 50 56 72 82 76 70 65 52 58 87 79 76 62 71 61 79 56 62 79 66\n",
      " 77 78 68 69 80 67 76  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0]\n",
      "Corrects:  [ 0  0 11  4  5  3  5  3 12  9  4  5  3 11  6  5  5  9  3  5  5  4  5  6\n",
      "  6  4  8  4  2  6  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0]\n",
      "[       nan        nan 0.171875   0.06451613 0.1        0.05357143\n",
      " 0.06944444 0.03658537 0.15789474 0.12857143 0.06153846 0.09615385\n",
      " 0.05172414 0.12643678 0.07594937 0.06578947 0.08064516 0.12676056\n",
      " 0.04918033 0.06329114 0.08928571 0.06451613 0.06329114 0.09090909\n",
      " 0.07792208 0.05128205 0.11764706 0.05797101 0.025      0.08955224\n",
      " 0.01315789        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:19<00:00, 104.61it/s]\n",
      "100%|██████████| 2000/2000 [00:08<00:00, 243.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Totals:  [ 0  0 64 62 50 56 72 82 76 70 65 52 58 87 79 76 62 71 61 79 56 62 79 66\n",
      " 77 78 68 69 80 67 76  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0]\n",
      "Corrects:  [ 0  0 16 14 10  3 10  4  3  2  2  4  2  1  3  2  2  2  2  0  0  1  0  0\n",
      "  3  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0]\n",
      "[       nan        nan 0.25       0.22580645 0.2        0.05357143\n",
      " 0.13888889 0.04878049 0.03947368 0.02857143 0.03076923 0.07692308\n",
      " 0.03448276 0.01149425 0.03797468 0.02631579 0.03225806 0.02816901\n",
      " 0.03278689 0.         0.         0.01612903 0.         0.\n",
      " 0.03896104 0.         0.         0.         0.0125     0.\n",
      " 0.                nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "the_experiment = SumOfDigits(lr=1e-3) #our model\n",
    "\n",
    "for i in range(10):\n",
    "    the_experiment.train_1_epoch(i)\n",
    "    the_experiment.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's visualize it ourselves! We will generate a simple dataset, print it, and pass it to our model to assess and visualize its performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real value of the sum of digits (target) :  11.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "dark"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computed value by the newtork (prediction) :  11\n"
     ]
    }
   ],
   "source": [
    "dataset_length = 1\n",
    "\n",
    "MNISTSum = MNISTSummation(min_len=2, max_len=5, dataset_len=dataset_length, train=True, transform=MNIST_TRANSFORM)\n",
    "\n",
    "x, target = MNISTSum.__getitem__(0)\n",
    "\n",
    "print(\"Real value of the sum of digits (target) : \",target.item())\n",
    "plt.imshow(torchvision.utils.make_grid(x, nrow=10).permute(1, 2, 0), cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "pred = the_experiment.test_after_training(x)\n",
    "print(\"Computed value by the newtork (prediction) : \", pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Be wary that this value may not be correct and you may need to re-run the previous cell multiple times to obtain a \"good\" result... It really depends on how much we trained the model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But at last we have (almost) successfully built up our MNIST Digits summer. The results are 'usually' good and prove the utility of DeepSets. But is there a catch ? If you followed closely the theoritical part, you may already have noticed it... What about the case where the domain of our function $f$ is **continous** ? There appears the limitations of this method that we'll discuss in our final section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III - Limitations of DeepSets and the representation of functions on sets\n",
    "Recall that we defined our backbone theorem as the following :\n",
    "<div class=\"alert alert-success\" style=\"margin-top: 1em\">\n",
    "    We denote by $\\mathcal{P}(\\mathfrak{X}) $ the power set of $\\mathfrak{X}$, i.e the set of the sets of $\\mathfrak{X}$.\n",
    "    Let $f : \\mathcal{P}(\\mathfrak{X}) \\rightarrow \\mathbb{R}$ where $\\mathfrak{X}$ is $\\textbf{countable}$ (i.e, its cardinality is smaller or equal to the number of elements in $\\mathbb{N}$. This includes both finite and countably infinite sets; e.g. $\\mathbb{N}$, $\\mathbb{Q}$, and subsets thereof). Then <b>$f$ is permutation-invariant if and only if it is sum-decomposable via the latent space $\\mathbb{R}$</b>.\n",
    "</div>\n",
    "<br>\n",
    "But what if the domain of our network (where the inputs \"belong\") is not countable? Said, $\\mathbb{R}$? In fact, we do have a second theorem, albeit slightly less strong.\n",
    "\n",
    "<div class=\"alert alert-success\" style=\"margin-top: 1em\">\n",
    "    <b>Uncountable Case</b> :\n",
    "    Let $M \\in \\mathbb{N}$, and let $f : [0, 1]^M \\rightarrow \\mathbb{R}$ be a continuous function. Then <b>$f$ is\n",
    "    permutation-invariant if and only if it is continuously sum-decomposable via $\\mathbb{R}^{M+1}$</b>\n",
    ".\n",
    "</div>\n",
    "<br>\n",
    "\n",
    "The proof is more complicated, we will not include it here (you can find it in the first paper refered). What this second theorem states is really interesting as it places a limit on the set size for a fixed finite-dimensional latent space. In particular, it shows that with a latent space of $M$ dimension is sufficient for representing all continuous permutation-invariant functions on sets of size $\\leq M$. If you want to feed the model larger sets, there's no guarantee that it can represent your target function. This means that **if we want to use continuous mappings, the dimension of the latent space must be at least the maximum set size** . The details of this implications are nicely discussed in the answering paper of [Wagstaff et al., 2019](https://arxiv.org/abs/1901.09006). I encourage you to read it, especially the sections 3 and 4, as it discusses both the limitations of this method and the importance of continuity in neural networks !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "As a conclusion, we showed in this notebook a new take on neural networks, providing a great framework for building invariant models on sets. This method however suffers from limitations when working with more complex domains such as $\\mathbb{R}$, and require attention when tuning the model. \n",
    "<br>\n",
    "As further reading, I can recommend these articles : \n",
    "* [Lee et al., 2018](https://arxiv.org/abs/1810.00825), proposing an attention-based architecture to implement set functions, Set Transformer.\n",
    "* [Bloem-Reddy and Teh, 2019](https://arxiv.org/abs/1901.06082) for a more theoretical take on invariances in neural networks.\n",
    "* [Vartak et al., 2017](https://papers.nips.cc/paper/7266-a-meta-learning-perspective-on-cold-start-recommendations-for-items) developed a recommender system for Twitter using DeepSets. User's preferences are summarized by the set of tweets they recently engaged with on the platform. This set is processed by a DeepSets architecture, and the output of this set function is then fed into another neural network that scores new tweets the user might find interesting.\n",
    "* [Maron et al., 2018](https://openreview.net/forum?id=Syx72jC9tm) for invariant and equivariant Graph Networks.\n",
    "\n",
    "The implications for this topic are endless and will certainly develop even more in the future !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix : permutation equivariance\n",
    "\n",
    "Permutation equivariance is another concept developed in the original paper by [Zaheer et al., 2017](https://arxiv.org/abs/1703.06114). Think of it as independance from permutation : if we take a function $f$ and a permutation $\\pi$, $f$ is permutation equivariant if \\begin{equation} f(\\{x_1, ... , x_M\\}) = \\{f_{\\pi(1)}(x), ... , f_{\\pi(M)}(x)\\} \\end{equation}\n",
    "<br>\n",
    "This different concept is discussed in the original paper, albeit slightly less developed and applied. Up to you to implement it in Pytorch !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Aucun(e)",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
